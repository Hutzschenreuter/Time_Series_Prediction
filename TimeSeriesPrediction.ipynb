{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas to work with our data\n",
    "# import NumPy\n",
    "# import matplotlib to plot charts and Seaborn to enhance charts\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "hours_per_week = 168 # equals 7*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv\n",
    "data_set = pd.read_csv('C:/Users/ahutz/OneDrive/Dokumente/ML/Daten/Energy/time_series_energy.csv')\n",
    "\n",
    "# preview data\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the data types (or dtypes) have been correctly interpreted\n",
    "data_set.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timestamp to datetime format\n",
    "data_set['timestamp'] = pd.to_datetime(data_set['timestamp'])\n",
    "data_set.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set timestamp as index for easy access to dataframe\n",
    "data_set.index = data_set['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missing values\n",
    "data_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate missing values\n",
    "data_set['price_day_ahead'].interpolate(method='linear', inplace=True)\n",
    "data_set['load_forecast'].interpolate(method='linear', inplace=True)\n",
    "data_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics for features\n",
    "data_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize time series data\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.lineplot(x=\"timestamp\", y=\"price_day_ahead\", data=data_set['2018'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize multiple time series as line plots\n",
    "data_plot = data_set['2018-05']\n",
    "f, axes = plt.subplots(3, 1, sharey=False, figsize=(18, 10))\n",
    "sns.lineplot(x=\"timestamp\", y=\"price_day_ahead\", data=data_plot, ax = axes[0])\n",
    "sns.lineplot(x=\"timestamp\", y=\"load_forecast\", data=data_plot, ax = axes[1])\n",
    "sns.lineplot(x=\"timestamp\", y=\"wind_forecast\", data=data_plot, ax = axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the distribution of the feature variables\n",
    "f, axes = plt.subplots(1, 3, sharey=False, figsize=(18, 6))\n",
    "sns.distplot(data_set['price_day_ahead'], kde=False, color=\"b\", ax = axes[0])\n",
    "sns.distplot(data_set['load_forecast'], kde=False, color=\"b\", ax = axes[1])\n",
    "sns.distplot(data_set['wind_forecast'], kde=False, color=\"b\", ax = axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the relation between variables \n",
    "#Scatter plots show how much one variable is affected by another\n",
    "#The relationship between two variables is called their correlation\n",
    "#negative vs positive correlation\n",
    "sns.pairplot(data_set['2018'][['load_forecast','wind_forecast','price_day_ahead']],plot_kws=dict(alpha=0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation matrix\n",
    "data_set.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract values from timestamps\n",
    "data_set['year'] = data_set['timestamp'].dt.year\n",
    "data_set['month_of_year'] = data_set['timestamp'].dt.month\n",
    "data_set['day_of_month'] = data_set['timestamp'].dt.day\n",
    "data_set['day_of_week'] = data_set['timestamp'].dt.weekday\n",
    "data_set['hour_of_day'] = data_set['timestamp'].dt.hour\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate additional feature\n",
    "data_set['price_last_week'] = data_set['price_day_ahead'].shift(hours_per_week)\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with nan values \n",
    "df = data_set.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation matrix\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training and testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of original\n",
    "df_original = df.copy()\n",
    "\n",
    "# use 3 years of data for training \n",
    "# use data week 1 2019 for testing\n",
    "train = df.ix['2016-01-08':'2019-01-07']\n",
    "test = df.ix['2019-01-07':'2019-01-13']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as benchmark we assume the electricity spot price last week and this week are the same (naive approach)\n",
    "y_hat = test.copy()\n",
    "y_hat['naive'] = test['price_last_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize actual prices together with predicted prices\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.lineplot(x='timestamp', y='price_day_ahead', label = 'Test', data = test[:'2019-01-13'])\n",
    "sns.lineplot(x='timestamp', y='naive', label = 'Naive', data = y_hat[:'2019-01-13'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize actual prices versus with predicted prices\n",
    "sns.scatterplot(x = test['price_day_ahead'], y = y_hat['naive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate root mean square error as metric for benchmark accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare predicted values to target\n",
    "# calculate difference between prediction and target, \n",
    "# then take square of difference (because differences can be positive or negative), \n",
    "# then divide the sum of all values by the number of observations (mean)\n",
    "# to get same unit of measurement of error as target data, take square root\n",
    "# smaller value means that predicted values are close to target values and vice versa\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse_naive = sqrt(mean_squared_error(test['price_day_ahead'], y_hat['naive']))\n",
    "print('RMSE Naive Test : %.3f' % rmse_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras is high-level neural networks API, written in Python and capable of running on top of TensorFlow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy & split the data\n",
    "df_ann = df_original.copy()\n",
    "train_nn = df_ann.ix['2016-01-08':'2019-01-07']\n",
    "test_nn = df_ann.ix['2019-01-07':'2019-01-13']\n",
    "\n",
    "# separate into feature set and target variable\n",
    "train_nn, test_nn = train_nn.drop(['timestamp'],1), test_nn.drop(['timestamp'],1)\n",
    "trainX, testX = train_nn.drop(['price_day_ahead'], 1), test_nn.drop(['price_day_ahead'], 1)\n",
    "trainY, testY = train_nn['price_day_ahead'], test_nn['price_day_ahead']\n",
    "\n",
    "trainX.to_numpy()\n",
    "testX.to_numpy()\n",
    "trainY.to_numpy()\n",
    "testY.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define structure of neural network, a feedforward neural network\n",
    "# input layer has 8 input nodes, one for each input feature (load forecast, wind forecast, time attributes and price_last_week)\n",
    "# three hidden layers with 12, 100 and 100 nodes, respectively\n",
    "# output layer has 1 output node, the predicted electricity spot price\n",
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "# configures the model for training\n",
    "# we use adam which uses Stochastic Gradient Descent and mse as loss function\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# summarizes the neural network structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train neural network model\n",
    "# network is trained for a total of 100 epochs, meaning that the model “sees” each individual training example 100 times\n",
    "# model parameters are updated using batches of size 100, meaning the number of examples per weight update\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=100, verbose=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the loss value for the model\n",
    "train_mse = model.evaluate(trainX, trainY, verbose=0)\n",
    "test_mse = model.evaluate(testX, testY, verbose=0)\n",
    "\n",
    "# make predictions\n",
    "trainPredict_nn = model.predict(trainX)\n",
    "testPredict_nn = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the predictions and target values on timeline\n",
    "y_hat['nn'] = testPredict_nn.reshape(-1)\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.lineplot(x='timestamp', y='price_day_ahead', label = 'Test', data = test[:'2019-01-11'])\n",
    "sns.lineplot(x='timestamp', y='naive', label = 'Naive', data = y_hat[:'2019-01-11'])\n",
    "sns.lineplot(x='timestamp', y='nn', label = 'NN', data = y_hat[:'2019-01-11'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize actual prices versus with predicted prices\n",
    "f, axes = plt.subplots(1, 2, sharey=False, figsize=(15, 6))\n",
    "sns.scatterplot(x=\"price_day_ahead\", y=\"naive\", data = y_hat[:'2019-01-11'], ax = axes[0])\n",
    "sns.scatterplot(x=\"price_day_ahead\", y=\"nn\", data = y_hat[:'2019-01-11'], ax = axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate rmse\n",
    "rmse_nn = sqrt(mean_squared_error(testY, testPredict_nn))\n",
    "print('RMSE NN Test : %.3f' % rmse_nn)\n",
    "print('RMSE Naive Test : %.3f' % rmse_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "def base_model():\n",
    "    model = Sequential()        \n",
    "    model.add(Dense(12,input_dim=9,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "X = trainX\n",
    "y = trainY\n",
    "\n",
    "my_model = KerasRegressor(build_fn=base_model, epochs=100, batch_size=168, verbose=0)    \n",
    "my_model.fit(X,y)\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(X,y)\n",
    "eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# create model\n",
    "model_kr = KerasRegressor(build_fn=base_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model_kr, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "X = trainX\n",
    "y = trainY\n",
    "grid_result = grid.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
